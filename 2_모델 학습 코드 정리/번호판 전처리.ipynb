{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1457d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentation\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_via_data(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "# VIA JSON 파일 경로\n",
    "via_json_path = r\"C:\\Users\\LMK\\Desktop\\12\\set_1\\train\\via.json\"\n",
    "output_dir = r\"C:\\Users\\LMK\\Desktop\\12\\set_1\\train\\transformed\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# JSON 파일 읽기\n",
    "via_data = load_via_data(via_json_path)\n",
    "\n",
    "# 데이터 파싱\n",
    "annotations = []\n",
    "for key, value in via_data.items():\n",
    "    filename = value['filename']\n",
    "    regions = value['regions']\n",
    "    polygons = []\n",
    "    labels = []\n",
    "    for region_key, region_value in regions.items():\n",
    "        shape_attributes = region_value['shape_attributes']\n",
    "        all_points_x = shape_attributes['all_points_x']\n",
    "        all_points_y = shape_attributes['all_points_y']\n",
    "        polygon = [(x, y) for x, y in zip(all_points_x, all_points_y)]\n",
    "        polygons.append(polygon)\n",
    "        labels.append(region_value['region_attributes']['name'])\n",
    "        labels.append(region_value['region_attributes']['label'])\n",
    "    annotations.append((filename, polygons, labels))\n",
    "\n",
    "# 어그멘테이션 정의\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.HueSaturationValue(p=0.2),\n",
    "    A.Resize(height=512, width=512, p=1.0),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "def clamp_keypoints(keypoints, width, height):\n",
    "    clamped_keypoints = []\n",
    "    for x, y in keypoints:\n",
    "        clamped_x = max(0, min(x, width - 1))\n",
    "        clamped_y = max(0, min(y, height - 1))\n",
    "        clamped_keypoints.append((clamped_x, clamped_y))\n",
    "    return clamped_keypoints\n",
    "\n",
    "def save_transformed_data(data, output_path):\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "# 변형된 이미지 저장 및 JSON 병합\n",
    "merged_via_data = load_via_data(via_json_path)\n",
    "all_transformed_data = {}\n",
    "\n",
    "for iteration in range(4):\n",
    "    print(f\"Iteration {iteration + 1}\")\n",
    "    via_transformed_data = {}\n",
    "\n",
    "    for filename, polygons, labels in annotations:\n",
    "        image_path = f\"C:\\\\Users\\\\LMK\\\\Desktop\\\\12\\\\set_1\\\\train\\\\{filename}\"\n",
    "\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Error: File '{image_path}' does not exist.\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Error: Failed to read the image '{image_path}'.\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        height, width, _ = image.shape\n",
    "\n",
    "        keypoints = [point for polygon in polygons for point in polygon]\n",
    "        clamped_keypoints = clamp_keypoints(keypoints, width, height)\n",
    "\n",
    "        transformed = transform(image=image, keypoints=clamped_keypoints)\n",
    "        transformed_image = transformed['image']\n",
    "        transformed_keypoints = transformed['keypoints']\n",
    "\n",
    "        transformed_polygons = []\n",
    "        index = 0\n",
    "        for polygon in polygons:\n",
    "            num_points = len(polygon)\n",
    "            transformed_polygon = transformed_keypoints[index:index+num_points]\n",
    "            transformed_polygons.append(transformed_polygon)\n",
    "            index += num_points\n",
    "\n",
    "        transformed_filename = f\"transformed_{iteration + 1}_{filename}\"\n",
    "        transformed_image_path = os.path.join(output_dir, transformed_filename)\n",
    "        \n",
    "        transformed_image_np = transformed_image.permute(1, 2, 0).cpu().numpy()\n",
    "        transformed_image_np = np.clip(transformed_image_np * 255, 0, 255).astype(np.uint8)\n",
    "        transformed_image_np = cv2.cvtColor(transformed_image_np, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(transformed_image_path, transformed_image_np)\n",
    "\n",
    "        new_polygons = [{'all_points_x': [int(x) for x, y in polygon], 'all_points_y': [int(y) for x, y in polygon]} for polygon in transformed_polygons]\n",
    "\n",
    "        new_key = f\"{filename}_transformed_{iteration + 1}\"\n",
    "        via_transformed_data[new_key] = {\n",
    "            'filename': transformed_filename,\n",
    "            'regions': {str(i): {'shape_attributes': new_polygons[i], 'region_attributes': {'name': labels[i]}, 'region_attributes' : {'label':\"license_plate\"}} for i in range(len(new_polygons))}\n",
    "        }\n",
    "\n",
    "    # 각 반복마다 변환된 데이터를 병합 데이터에 추가\n",
    "    all_transformed_data.update(via_transformed_data)\n",
    "\n",
    "    # 각 반복마다 변환된 데이터 저장\n",
    "    transformed_output_path = os.path.join(output_dir, f'via_transformed_{iteration + 1}.json')\n",
    "    save_transformed_data(via_transformed_data, transformed_output_path)\n",
    "\n",
    "    print(f\"Total processed images in iteration {iteration + 1}: {len(via_transformed_data)}\")\n",
    "\n",
    "# 모든 변환된 데이터를 병합\n",
    "merged_via_data.update(all_transformed_data)\n",
    "\n",
    "merged_output_path = os.path.join(output_dir, 'via_merged.json')\n",
    "save_transformed_data(merged_via_data, merged_output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f03dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentation 후 이미지 시각화까지\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# VIA JSON 파일 경로\n",
    "via_json_path = r\"C:\\Users\\LMK\\Desktop\\12\\set_1\\train\\via.json\"\n",
    "\n",
    "# JSON 파일 읽기\n",
    "with open(via_json_path, 'r') as f:\n",
    "    via_data = json.load(f)\n",
    "\n",
    "# 데이터 파싱\n",
    "annotations = []\n",
    "for key, value in via_data.items():\n",
    "    filename = value['filename']\n",
    "    regions = value['regions']\n",
    "    polygons = []\n",
    "    labels = []\n",
    "    for region_key, region_value in regions.items():\n",
    "        shape_attributes = region_value['shape_attributes']\n",
    "        all_points_x = shape_attributes['all_points_x']\n",
    "        all_points_y = shape_attributes['all_points_y']\n",
    "        polygon = [(x, y) for x, y in zip(all_points_x, all_points_y)]\n",
    "        polygons.append(polygon)\n",
    "        labels.append(region_value['region_attributes']['name'])\n",
    "    annotations.append((filename, polygons, labels))\n",
    "\n",
    "# 어그멘테이션 정의\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.HueSaturationValue(p=0.2),\n",
    "    A.Resize(height=512, width=512, p=1.0),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "], keypoint_params=A.KeypointParams(format='xy'))\n",
    "\n",
    "def visualize(image, polygons):\n",
    "    img = image.copy()\n",
    "    for polygon in polygons:\n",
    "        polygon = np.array(polygon, np.int32)\n",
    "        polygon = polygon.reshape((-1, 1, 2))\n",
    "        cv2.polylines(img, [polygon], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# 변형된 이미지 저장 경로\n",
    "output_dir = r\"C:\\Users\\LMK\\Desktop\\12\\set_1\\train\\transformed\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 예시로 첫 번째 이미지 처리\n",
    "filename, polygons, labels = annotations[0]\n",
    "image_path = f\"C:\\\\Users\\\\LMK\\\\Desktop\\\\12\\\\set_1\\\\train\\\\{filename}\"\n",
    "\n",
    "# 파일 존재 여부 확인\n",
    "if not os.path.exists(image_path):\n",
    "    print(f\"Error: File '{image_path}' does not exist.\")\n",
    "else:\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Failed to read the image '{image_path}'.\")\n",
    "    else:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        keypoints = [point for polygon in polygons for point in polygon]\n",
    "\n",
    "        # 어그멘테이션 적용\n",
    "        transformed = transform(image=image, keypoints=keypoints)\n",
    "        transformed_image = transformed['image']\n",
    "        transformed_keypoints = transformed['keypoints']\n",
    "\n",
    "        # 변환된 키포인트를 폴리곤 형태로 재구성\n",
    "        transformed_polygons = []\n",
    "        index = 0\n",
    "        for polygon in polygons:\n",
    "            num_points = len(polygon)\n",
    "            transformed_polygon = transformed_keypoints[index:index+num_points]\n",
    "            transformed_polygons.append(transformed_polygon)\n",
    "            index += num_points\n",
    "\n",
    "        # 어그멘테이션 후 이미지와 폴리곤 시각화\n",
    "        visualize(transformed_image.permute(1, 2, 0).numpy(), transformed_polygons)\n",
    "\n",
    "        # 변형된 이미지 저장\n",
    "        transformed_filename = f\"transformed_{filename}\"\n",
    "        transformed_image_path = os.path.join(output_dir, transformed_filename)\n",
    "        cv2.imwrite(transformed_image_path, transformed_image.permute(1, 2, 0).numpy()[:, :, ::-1] * 255)\n",
    "\n",
    "        # 변환된 폴리곤을 원래 형식으로 변환\n",
    "        new_polygons = [{'all_points_x': [int(x) for x, y in polygon], 'all_points_y': [int(y) for x, y in polygon]} for polygon in transformed_polygons]\n",
    "\n",
    "        # 변환된 데이터 저장\n",
    "        via_data[key]['filename'] = transformed_filename\n",
    "        via_data[key]['regions'] = {str(i): {'shape_attributes': new_polygons[i], 'region_attributes': {'label': labels[i]}} for i in range(len(new_polygons))}\n",
    "\n",
    "        # 변환된 JSON 파일 저장\n",
    "        with open(r\"C:\\Users\\LMK\\Desktop\\12\\set_1\\train\\via_t.json\", 'w') as f:\n",
    "            json.dump(via_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52096832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#섞기\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "# JSON 파일 경로\n",
    "via_json_path = r\"C:\\Users\\LMK\\Desktop\\aug2\\val\\via_merged.json\"\n",
    "shuffled_json_path = r\"C:\\Users\\LMK\\Desktop\\aug2\\val\\via_merged.json\"\n",
    "\n",
    "# JSON 파일 읽기\n",
    "def load_via_data(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "via_data = load_via_data(via_json_path)\n",
    "\n",
    "# 데이터의 키를 리스트로 추출하여 무작위로 섞기\n",
    "keys = list(via_data.keys())\n",
    "random.shuffle(keys)\n",
    "\n",
    "# 무작위로 섞인 순서로 새로운 사전 생성\n",
    "shuffled_via_data = {key: via_data[key] for key in keys}\n",
    "\n",
    "# 새로운 JSON 파일로 저장\n",
    "with open(shuffled_json_path, 'w') as f:\n",
    "    json.dump(shuffled_via_data, f, indent=4)\n",
    "\n",
    "print(f\"Shuffled JSON data saved to {shuffled_json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444382d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "# JSON 파일 경로\n",
    "via_json_path = r\"C:\\Users\\LMK\\Desktop\\aug2\\val\\via_merged.json\"\n",
    "shuffled_json_path = r\"C:\\Users\\LMK\\Desktop\\aug2\\val\\via_merged1.json\"\n",
    "\n",
    "# JSON 파일 읽기\n",
    "def load_via_data(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "via_data = load_via_data(via_json_path)\n",
    "\n",
    "# 데이터 섞기 전 로그\n",
    "print(\"Before shuffling:\")\n",
    "for key, value in via_data.items():\n",
    "    for region_key, region_value in value['regions'].items():\n",
    "        if 'label' in region_value['region_attributes']:\n",
    "            print(f\"{key}: {region_value['region_attributes']['label']}\")\n",
    "\n",
    "# 데이터의 키를 리스트로 추출하여 무작위로 섞기\n",
    "keys = list(via_data.keys())\n",
    "random.shuffle(keys)\n",
    "\n",
    "# 무작위로 섞인 순서로 새로운 사전 생성\n",
    "shuffled_via_data = {key: via_data[key] for key in keys}\n",
    "\n",
    "# 데이터 섞기 후 로그\n",
    "print(\"\\nAfter shuffling:\")\n",
    "for key, value in shuffled_via_data.items():\n",
    "    for region_key, region_value in value['regions'].items():\n",
    "        if 'label' in region_value['region_attributes']:\n",
    "            print(f\"{key}: {region_value['region_attributes']['label']}\")\n",
    "\n",
    "# 새로운 JSON 파일로 저장\n",
    "with open(shuffled_json_path, 'w') as f:\n",
    "    json.dump(shuffled_via_data, f, indent=4)\n",
    "\n",
    "print(f\"Shuffled JSON data saved to {shuffled_json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07718b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train val 분할\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def get_random_samples(source_files, num_samples):\n",
    "    return random.sample(source_files, num_samples)\n",
    "\n",
    "def copy_files(files, source_dir, destination_dir):\n",
    "    os.makedirs(destination_dir, exist_ok=True)\n",
    "    for file in files:\n",
    "        # 이미지 파일 복사\n",
    "        shutil.copy(os.path.join(source_dir, file), os.path.join(destination_dir, file))\n",
    "        # 동일한 이름의 라벨링 파일 복사\n",
    "        label_file = os.path.splitext(file)[0] + '.xml'  # 예: image1.jpg -> image1.xml\n",
    "        if os.path.exists(os.path.join(source_dir, label_file)):\n",
    "            shutil.copy(os.path.join(source_dir, label_file), os.path.join(destination_dir, label_file))\n",
    "\n",
    "def create_datasets(source_dir, output_base_dir, num_train_samples=380, num_val_samples=200, num_sets=1):\n",
    "    # 이미지 파일만 선택 (확장자 .png 또는 .jpeg)\n",
    "    source_files = [f for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f)) and (f.endswith('.png') or f.endswith('.jpeg') or f.endswith('.jpg'))]  # '.jpg' 확장자도 추가\n",
    "\n",
    "    if len(source_files) < (num_train_samples + num_val_samples):\n",
    "        raise ValueError(\"Source directory does not contain enough images to create the desired dataset sizes.\")\n",
    "\n",
    "    used_files = set()\n",
    "    \n",
    "    for i in range(1, num_sets + 1):\n",
    "        available_files = list(set(source_files) - used_files)\n",
    "        \n",
    "        train_samples = get_random_samples(available_files, num_train_samples)\n",
    "        used_files.update(train_samples)\n",
    "        \n",
    "        available_files = list(set(source_files) - used_files)\n",
    "        val_samples = get_random_samples(available_files, num_val_samples)\n",
    "        used_files.update(val_samples)\n",
    "        \n",
    "        output_train_dir = os.path.join(output_base_dir, f'set_{i}', 'train')\n",
    "        output_val_dir = os.path.join(output_base_dir, f'set_{i}', 'val')\n",
    "        \n",
    "        copy_files(train_samples, source_dir, output_train_dir)\n",
    "        copy_files(val_samples, source_dir, output_val_dir)\n",
    "        \n",
    "        print(f\"Set {i} - Train samples: {len(train_samples)}\")\n",
    "        print(f\"Set {i} - Val samples: {len(val_samples)}\")\n",
    "\n",
    "# 디렉토리 경로 설정\n",
    "source_dir = r\"C:\\Users\\LMK\\Desktop\\plate_new\\images\"\n",
    "output_base_dir = r\"C:\\Users\\LMK\\Desktop\\plate_new\\plate\"\n",
    "\n",
    "# 데이터셋 생성\n",
    "create_datasets(source_dir, output_base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09380930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#json 내부 이미지와 라벨 매칭 여부\n",
    "import json\n",
    "import os\n",
    "\n",
    "def load_json(path):\n",
    "    \"\"\"\n",
    "    JSON 파일을 불러오는 함수입니다.\n",
    "    \"\"\"\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def get_image_filenames(folder_path, extensions=['.jpg', '.jpeg', '.png']):\n",
    "    \"\"\"\n",
    "    폴더 내의 이미지 파일 이름을 불러오는 함수입니다.\n",
    "    \"\"\"\n",
    "    return [f for f in os.listdir(folder_path) if os.path.splitext(f)[1].lower() in extensions]\n",
    "\n",
    "def check_images_in_json(json_data, image_filenames):\n",
    "    \"\"\"\n",
    "    JSON 데이터에 모든 이미지 파일 정보가 포함되어 있는지 확인하는 함수입니다.\n",
    "    \"\"\"\n",
    "    json_filenames = [entry['file_name'] for entry in json_data.values()]\n",
    "    missing_files = [filename for filename in image_filenames if filename not in json_filenames]\n",
    "    extra_files = [filename for filename in json_filenames if filename not in image_filenames]\n",
    "    return missing_files, extra_files\n",
    "\n",
    "# 경로 설정\n",
    "json_path = r\"C:\\Users\\LMK\\Desktop\\aug2\\val\\custom_var.json\"\n",
    "image_folder = r\"C:\\Users\\LMK\\Desktop\\aug2\\val\"\n",
    "\n",
    "# JSON 파일 및 이미지 파일 불러오기\n",
    "json_data = load_json(json_path)\n",
    "image_filenames = get_image_filenames(image_folder)\n",
    "\n",
    "# JSON 데이터 확인\n",
    "missing_files, extra_files = check_images_in_json(json_data, image_filenames)\n",
    "\n",
    "# JSON 파일 내부의 file_name 개수 출력\n",
    "json_image_filenames_count = sum(1 for entry in json_data.values() if 'file_name' in entry)\n",
    "\n",
    "print(f\"JSON 파일 내의 'file_name' 개수: {json_image_filenames_count}\")\n",
    "\n",
    "if missing_files:\n",
    "    print(\"JSON에 포함되지 않은 이미지 파일들:\")\n",
    "    for file in missing_files:\n",
    "        print(file)\n",
    "else:\n",
    "    print(\"모든 이미지 파일이 JSON에 포함되어 있습니다.\")\n",
    "\n",
    "if extra_files:\n",
    "    print(\"폴더에 없는 JSON 파일들:\")\n",
    "    for file in extra_files:\n",
    "        print(file)\n",
    "else:\n",
    "    print(\"모든 JSON 파일이 폴더에 존재합니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97514305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 파일 숫자 세기\n",
    "import os\n",
    "\n",
    "def count_image_files(directory, extensions=['.jpg', '.jpeg', '.png', '.bmp', '.gif']):\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if any(file.lower().endswith(ext) for ext in extensions):\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "# 이미지 파일이 있는 폴더 경로\n",
    "image_folder_path = r\"C:\\Users\\LMK\\Desktop\\plate_new\\images\"\n",
    "# 이미지 파일 개수 세기\n",
    "num_images = count_image_files(image_folder_path)\n",
    "print(f\"Total number of image files: {num_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee67f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xml 수합후 json via로 병합\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "\n",
    "# Function to parse a single XML file and convert rect to polygon\n",
    "def parse_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    filename = root.find('filename').text\n",
    "\n",
    "    annotations = []\n",
    "    for obj in root.findall('object'):\n",
    "        name = obj.find('name').text\n",
    "        xmin = int(obj.find('bndbox/xmin').text)\n",
    "        ymin = int(obj.find('bndbox/ymin').text)\n",
    "        xmax = int(obj.find('bndbox/xmax').text)\n",
    "        ymax = int(obj.find('bndbox/ymax').text)\n",
    "\n",
    "        # Convert rect to polygon\n",
    "        annotations.append({\n",
    "            \"shape_attributes\": {\n",
    "                \"name\": \"polygon\",\n",
    "                \"all_points_x\": [xmin, xmax, xmax, xmin],\n",
    "                \"all_points_y\": [ymin, ymin, ymax, ymax]\n",
    "            },\n",
    "            \"region_attributes\": {\n",
    "                \"name\": name,\n",
    "                \"label\":\"license_plate\"\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    return filename, annotations\n",
    "\n",
    "# Function to convert parsed data to VIA format\n",
    "def convert_to_via_format(parsed_data):\n",
    "    via_data = {}\n",
    "    for filename, annotations in parsed_data:\n",
    "        via_data[filename] = {\n",
    "            \"filename\": filename,\n",
    "            \"size\": -1,  # Size is unknown\n",
    "            \"regions\": {str(i): annotations[i] for i in range(len(annotations))},\n",
    "            \"file_attributes\": {}\n",
    "        }\n",
    "    return via_data\n",
    "\n",
    "# Directory containing XML files\n",
    "xml_dir = r\"C:\\Users\\LMK\\Desktop\\plate_new\\plate\\set_1\\train\"\n",
    "# Parse all XML files in the directory\n",
    "parsed_data = []\n",
    "for xml_file in os.listdir(xml_dir):\n",
    "    if xml_file.endswith('.xml'):\n",
    "        parsed_data.append(parse_xml(os.path.join(xml_dir, xml_file)))\n",
    "\n",
    "# Convert parsed data to VIA format\n",
    "via_data = convert_to_via_format(parsed_data)\n",
    "\n",
    "# Write VIA data to a JSON file in the xml_dir directory\n",
    "via_json_file = os.path.join(xml_dir, 'via.json')\n",
    "with open(via_json_file, 'w') as f:\n",
    "    json.dump(via_data, f, indent=4)\n",
    "\n",
    "print(f\"VIA annotations have been saved to {via_json_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ceba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 삭제 후 라벨링 매칭여부\n",
    "import os\n",
    "\n",
    "def check_image_label_pairs(folder_path, image_extensions=['.jpg', '.jpeg', '.png'], label_extensions=['.json', '.xml']):\n",
    "    \"\"\"\n",
    "    이미지와 라벨링 데이터가 동일한 이름으로 짝지어져 있는지 확인합니다.\n",
    "\n",
    "    Args:\n",
    "    folder_path (str): 파일을 검사할 폴더 경로\n",
    "    image_extensions (list): 이미지 파일 확장자 리스트\n",
    "    label_extensions (list): 라벨 파일 확장자 리스트\n",
    "\n",
    "    Returns:\n",
    "    dict: 짝지어지지 않은 이미지 및 라벨 파일 목록\n",
    "    \"\"\"\n",
    "    # 폴더 내의 모든 파일 목록 가져오기\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    # 이미지 파일 및 라벨 파일 필터링\n",
    "    image_files = [os.path.splitext(file)[0] for file in files if os.path.splitext(file)[1].lower() in image_extensions]\n",
    "    label_files = [os.path.splitext(file)[0] for file in files if os.path.splitext(file)[1].lower() in label_extensions]\n",
    "    \n",
    "    # 이미지 파일 중 라벨이 없는 파일 찾기\n",
    "    images_without_labels = [file for file in image_files if file not in label_files]\n",
    "    \n",
    "    # 라벨 파일 중 이미지가 없는 파일 찾기\n",
    "    labels_without_images = [file for file in label_files if file not in image_files]\n",
    "    \n",
    "    return {\n",
    "        \"images_without_labels\": images_without_labels,\n",
    "        \"labels_without_images\": labels_without_images\n",
    "    }\n",
    "\n",
    "# 폴더 경로 지정\n",
    "folder_path = r\"C:\\Users\\LMK\\Desktop\\plate_new\\plate\\set_1\\val\"\n",
    "\n",
    "# 함수 호출\n",
    "unpaired_files = check_image_label_pairs(folder_path)\n",
    "\n",
    "if unpaired_files[\"images_without_labels\"]:\n",
    "    print(\"라벨이 없는 이미지 파일:\")\n",
    "    for file in unpaired_files[\"images_without_labels\"]:\n",
    "        print(f\"{file}\")\n",
    "else:\n",
    "    print(\"라벨이 없는 이미지 파일이 없습니다.\")\n",
    "\n",
    "if unpaired_files[\"labels_without_images\"]:\n",
    "    print(\"이미지가 없는 라벨 파일:\")\n",
    "    for file in unpaired_files[\"labels_without_images\"]:\n",
    "        print(f\"{file}\")\n",
    "else:\n",
    "    print(\"이미지가 없는 라벨 파일이 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff3f376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb598d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da02000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc09206b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
